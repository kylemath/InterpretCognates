{"role":"user","message":{"content":[{"type":"text","text":"<user_query>\nSearch the codebase thoroughly for:\n\n1. The frontend code that renders the 3D PCA \"Manifold Cloud\" scatter plot. Look in /Users/kylemathewson/InterpretCognates/backend/app/static/app.js for functions related to PCA, manifold cloud, 3D scatter, and the \"Language Clusters (Raw)\" / \"Concept Clusters (Mean-Centered)\" toggle buttons.\n\n2. The backend code that computes the mean-centered PCA projection. Look in /Users/kylemathewson/InterpretCognates/backend/app/modeling.py for functions like `project_embeddings`, `project_embeddings_mean_centered`, or anything related to PCA projection and mean-centering.\n\n3. The backend API endpoint that serves the PCA data — look in /Users/kylemathewson/InterpretCognates/backend/app/main.py for the `/api/analyze` endpoint or similar.\n\nReturn the FULL code of all relevant functions with their line numbers. Be very thorough — include the complete function bodies, not just signatures.\n</user_query>"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Searching for the 3D PCA scatter plot frontend code, mean-centered PCA projection backend code, and the API endpoint. Reading the relevant files."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Searching for HTML files and any references to \"Manifold Cloud\" or toggle buttons:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Reading `index.html` for the toggle button context:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"## 1. Frontend code: 3D PCA scatter plot rendering\n\n### `renderScatter` function (lines 430-480 in `/Users/kylemathewson/InterpretCognates/backend/app/static/app.js`)\n\n```430:480:backend/app/static/app.js\nfunction renderScatter(points, sentences) {\n  // Group points by language family for colored traces\n  const byFamily = new Map();\n  points.forEach((p, i) => {\n    const family = langFamily(p.label);\n    if (!byFamily.has(family)) {\n      byFamily.set(family, { x: [], y: [], z: [], text: [], hover: [] });\n    }\n    const g = byFamily.get(family);\n    g.x.push(p.x);\n    g.y.push(p.y);\n    g.z.push(p.z ?? 0);\n    g.text.push(langName(p.label));\n    g.hover.push(`<b>${langName(p.label)}</b><br>${family}<br><i>${sentences[i]}</i>`);\n  });\n\n  const traces = [...byFamily.entries()].map(([family, g]) => ({\n    type: \"scatter3d\",\n    mode: \"markers+text\",\n    name: family,\n    x: g.x,\n    y: g.y,\n    z: g.z,\n    text: g.text,\n    textposition: \"top center\",\n    hovertext: g.hover,\n    hoverinfo: \"text\",\n    marker: {\n      size: 7,\n      color: FAMILY_COLORS[family] || FAMILY_COLORS[\"Unknown\"],\n      opacity: 0.9,\n    },\n    textfont: { size: 11 },\n  }));\n\n  Plotly.newPlot(\n    \"scatter\",\n    traces,\n    {\n      margin: { l: 0, r: 0, t: 10, b: 0 },\n      scene: {\n        xaxis: { title: \"PC 1\", showgrid: true, zeroline: false },\n        yaxis: { title: \"PC 2\", showgrid: true, zeroline: false },\n        zaxis: { title: \"PC 3\", showgrid: true, zeroline: false },\n        camera: { eye: { x: 1.4, y: 1.4, z: 1.0 } },\n      },\n      legend: { orientation: \"h\", y: -0.05, font: { size: 11 } },\n    },\n    { responsive: true },\n  );\n}\n```\n\n### PCA mode toggle buttons (lines 707-725 in `/Users/kylemathewson/InterpretCognates/backend/app/static/app.js`)\n\n```707:725:backend/app/static/app.js\nconst pcaRawBtn = document.getElementById(\"pcaRawBtn\");\nconst pcaCenteredBtn = document.getElementById(\"pcaCenteredBtn\");\n\nif (pcaRawBtn && pcaCenteredBtn) {\n  pcaRawBtn.addEventListener(\"click\", () => {\n    if (window._lastData) {\n      pcaRawBtn.classList.add(\"active\");\n      pcaCenteredBtn.classList.remove(\"active\");\n      renderScatter(window._lastData.embedding_points, window._lastData.sentences);\n    }\n  });\n  pcaCenteredBtn.addEventListener(\"click\", () => {\n    if (window._lastData && window._lastData.embedding_points_centered) {\n      pcaCenteredBtn.classList.add(\"active\");\n      pcaRawBtn.classList.remove(\"active\");\n      renderScatter(window._lastData.embedding_points_centered, window._lastData.sentences);\n    }\n  });\n}\n```\n\n### Data storage in `runAnalysis` (lines 649-692 in `/Users/kylemathewson/InterpretCognates/backend/app/static/app.js`)\n\n```649:692:backend/app/static/app.js\nasync function runAnalysis() {\n  runBtn.disabled = true;\n  runBtn.textContent = \"Analyzing...\";\n  try {\n    const sourceLang = sourceLangInput.value.trim();\n    const targetLangs = [...selectedLangs].filter((code) => code !== sourceLang);\n    if (!targetLangs.length) {\n      throw new Error(\"Pick at least one target language\");\n    }\n\n    const payload = {\n      concept: conceptInput.value.trim(),\n      source_lang: sourceLang,\n      target_langs: targetLangs,\n      context_template: contextTemplateInput.value.trim(),\n      isotropy_corrected: isotropyToggle.checked,\n    };\n\n    const response = await fetch(\"/api/analyze\", {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify(payload),\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error ${response.status}`);\n    }\n\n    const data = await response.json();\n    renderTranslations(data.translations);\n    renderScatter(data.embedding_points, data.sentences);\n    // Store centered points for toggle\n    window._lastData = data;\n    window._pcaMode = \"raw\";\n    // data.labels are NLLB codes; renderSimilarity resolves names internally\n    renderSimilarity(data.labels, data.similarity_matrix);\n    renderAttentionMaps(data.attention_maps);\n  } catch (error) {\n    translationsEl.innerHTML = `<div class=\"translationItem\">Error: ${error.message}</div>`;\n  } finally {\n    runBtn.disabled = false;\n    runBtn.textContent = \"Analyze Concept Geometry\";\n  }\n}\n```\n\n### HTML toggle buttons (lines 66-70 in `/Users/kylemathewson/InterpretCognates/backend/app/static/index.html`)\n\n```66:70:backend/app/static/index.html\n        <h2>Concept Manifold Cloud (PCA)</h2>\n        <div class=\"vizToggle\">\n          <button id=\"pcaRawBtn\" class=\"toggleBtn active\">Language Clusters (Raw)</button>\n          <button id=\"pcaCenteredBtn\" class=\"toggleBtn\">Concept Clusters (Mean-Centered)</button>\n        </div>\n```\n\n---\n\n## 2. Backend code: mean-centered PCA projection\n\n### `project_embeddings_mean_centered` function (lines 214-241 in `/Users/kylemathewson/InterpretCognates/backend/app/modeling.py`)\n\n```214:241:backend/app/modeling.py\ndef project_embeddings_mean_centered(\n    vectors: list[np.ndarray], labels: list[str], language_ids: list[str]\n) -> dict[str, Any]:\n    array = np.array(vectors)\n    lang_set = sorted(set(language_ids))\n    lang_means = {}\n    for lang in lang_set:\n        indices = [i for i, l in enumerate(language_ids) if l == lang]\n        lang_means[lang] = array[indices].mean(axis=0)\n    centered = np.array([array[i] - lang_means[language_ids[i]] for i in range(len(vectors))])\n\n    n = len(vectors)\n    n_components = min(3, n, array.shape[1])\n    raw_proj = PCA(n_components=n_components).fit_transform(array)\n    centered_proj = PCA(n_components=n_components).fit_transform(centered)\n\n    def _to_points(proj, lbls):\n        points = []\n        for i, label in enumerate(lbls):\n            points.append({\n                \"label\": label,\n                \"x\": float(proj[i, 0]),\n                \"y\": float(proj[i, 1]),\n                \"z\": float(proj[i, 2]) if n_components >= 3 else 0.0,\n            })\n        return points\n\n    return {\"raw\": _to_points(raw_proj, labels), \"centered\": _to_points(centered_proj, labels)}\n```\n\n### `project_embeddings` function (raw PCA, lines 125-141 in `/Users/kylemathewson/InterpretCognates/backend/app/modeling.py`)\n\n```125:141:backend/app/modeling.py\ndef project_embeddings(vectors: list[np.ndarray], labels: list[str]) -> list[dict[str, Any]]:\n    n = len(vectors)\n    if n < 2:\n        return [{\"label\": labels[0], \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}]\n    array = np.array(vectors)\n    n_components = min(3, n, array.shape[1])\n    projected = PCA(n_components=n_components).fit_transform(array)\n    points = []\n    for i, label in enumerate(labels):\n        point: dict[str, Any] = {\n            \"label\": label,\n            \"x\": float(projected[i, 0]),\n            \"y\": float(projected[i, 1]),\n            \"z\": float(projected[i, 2]) if n_components >= 3 else 0.0,\n        }\n        points.append(point)\n    return points\n```\n\n---\n\n## 3. Backend API endpoint: `/api/analyze`\n\n### `/api/analyze` endpoint (lines 120-161 in `/Users/kylemathewson/InterpretCognates/backend/app/main.py`)\n\n```120:161:backend/app/main.py\n@app.post(\"/api/analyze\")\ndef analyze(payload: AnalyzeRequest) -> dict:\n    source_sentence = payload.context_template.format(word=payload.concept)\n\n    labels = [payload.source_lang]\n    language_ids = [payload.source_lang]\n    sentences = [source_sentence]\n    vectors = [embed_text(source_sentence, payload.source_lang)]\n    translations = []\n    attention_maps = []\n\n    for lang in payload.target_langs:\n        translated_sentence = translate_text(source_sentence, payload.source_lang, lang)\n        translations.append({\"lang\": lang, \"text\": translated_sentence})\n        labels.append(lang)\n        language_ids.append(lang)\n        sentences.append(translated_sentence)\n        vectors.append(embed_text(translated_sentence, lang))\n        attention = cross_attention_map(source_sentence, payload.source_lang, translated_sentence, lang)\n        attention_maps.append({\"lang\": lang, **attention})\n\n    points = project_embeddings(vectors, labels)\n\n    if payload.isotropy_corrected:\n        similarity = sentence_similarity_matrix_corrected(vectors)\n    else:\n        similarity = sentence_similarity_matrix(vectors)\n\n    mean_centered = project_embeddings_mean_centered(vectors, labels, language_ids)\n\n    return {\n        \"concept\": payload.concept,\n        \"source_sentence\": source_sentence,\n        \"labels\": labels,\n        \"language_ids\": language_ids,\n        \"sentences\": sentences,\n        \"translations\": translations,\n        \"embedding_points\": points,\n        \"embedding_points_centered\": mean_centered[\"centered\"],\n        \"similarity_matrix\": similarity,\n        \"attention_maps\": attention_maps,\n    }\n```\n\n### Request model (lines 47-52 in `/Users/kylemathewson/InterpretCognates/backend/app/main.py`)\n\n```47:52:backend/app/main.py\nclass AnalyzeRequest(BaseModel):\n    concept: str = Field(..., min_length=1, max_length=80)\n    source_lang: str = \"eng_Latn\"\n    target_langs: list[str] = Field(default_factory=lambda: [\"spa_Latn\", \"fra_Latn\", \"deu_Latn\"])\n    context_template: str = \"I saw a {word} near the river.\"\n    isotropy_corrected: bool = False\n```\n\n---\n\n## Summary\n\n- Frontend: `renderScatter` creates the 3D Plotly scatter plot; toggle handlers switch between raw and mean-centered data stored in `window._lastData`.\n- Backend: `project_embeddings_mean_centered` computes per-language means, subtracts them, then runs PCA on the centered vectors; returns both raw and centered projections.\n- API: `/api/analyze` calls both `project_embeddings` (raw) and `project_embeddings_mean_centered`, returning `embedding_points` and `embedding_points_centered` for the toggle."}]}}