{"role":"user","message":{"content":[{"type":"text","text":"<user_query>\nThoroughly explore the entire codebase at /Users/kylemathewson/InterpretCognates. I need to understand:\n1. The full directory structure\n2. What frontend files exist (especially HTML/JS)\n3. What backend/analysis files exist\n4. What data files exist\n5. What the current app does - look at any main entry points, servers, etc.\n\nReturn a comprehensive overview of every important file, its purpose, and the project structure.\n</user_query>"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Exploring the codebase. Gathering directory structure and identifying key files."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Exploring the directory structure and reading key files:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Reading the remaining backend Python files:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Checking the research directory for additional context:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"## Codebase overview: InterpretCognates\n\n### Project structure\n\n```\nInterpretCognates/\n├── README.md                    # Project documentation & setup instructions\n├── backend/                     # Python FastAPI backend\n│   ├── app/\n│   │   ├── __init__.py         # Empty package init\n│   │   ├── main.py             # FastAPI application & API endpoints\n│   │   ├── modeling.py         # Core ML functions (NLLB model, embeddings, attention)\n│   │   ├── benchmarks.py       # Research experiments & validation functions\n│   │   ├── static/             # Frontend files\n│   │   │   ├── index.html      # Main UI page\n│   │   │   ├── app.js          # Frontend JavaScript logic\n│   │   │   └── styles.css      # UI styling\n│   │   └── data/               # Research datasets\n│   │       ├── swadesh_100.json    # Swadesh 100 core vocabulary (40 languages)\n│   │       └── color_terms.json    # Berlin & Kay color terms (30 languages)\n│   ├── requirements.txt        # Python dependencies\n│   └── venv/                   # Virtual environment (excluded from analysis)\n└── research/                   # Research documentation\n    ├── executive_summary.md    # Meeting synthesis & roadmap\n    ├── agent_a_bib.md          # NLP interpretability bibliography\n    ├── agent_b_bib.md          # Cognitive science bibliography\n    └── meeting.md              # Meeting notes\n```\n\n---\n\n### Frontend files (HTML/JS/CSS)\n\n#### 1. `backend/app/static/index.html` (136 lines)\n- Single-page HTML app\n- Sections:\n  - Hero with project description\n  - Controls: concept input, source language, context template, language picker (80+ languages)\n  - Translation outputs display\n  - PCA visualization toggle (raw vs mean-centered)\n  - Similarity matrix heatmap\n  - Cross-attention alignment visualization\n  - Scientific experiments panel (4 experiments)\n- Uses Plotly.js for visualizations\n\n#### 2. `backend/app/static/app.js` (938 lines)\n- Frontend logic\n- Language management:\n  - 80+ languages organized by family (Indo-European, Sino-Tibetan, etc.)\n  - Presets: 10, 30, 60, or all languages\n  - Search/filter\n- Visualization functions:\n  - `renderScatter()`: 3D PCA scatter plot\n  - `renderSimilarity()`: Cosine similarity heatmap with family grouping\n  - `renderAttentionMaps()`: Cross-attention heatmaps (unified + detail views)\n  - `renderTranslations()`: Translation display\n- Experiment handlers:\n  - Swadesh convergence ranking\n  - Color circle (Berlin & Kay)\n  - Colexification test (CLICS²)\n  - Phylogenetic distance matrix\n- API integration: POST requests to `/api/*` endpoints\n\n#### 3. `backend/app/static/styles.css` (332 lines)\n- Styling\n- Color scheme: blue/purple primary, family color coding\n- Responsive layout\n- Component styles: cards, buttons, language picker, experiment grid\n\n---\n\n### Backend/analysis files (Python)\n\n#### 1. `backend/app/main.py` (373 lines) — FastAPI application\nEntry point: `uvicorn app.main:app --reload`\n\nAPI endpoints:\n- `GET /` → Serves `index.html`\n- `POST /api/analyze` → Main analysis endpoint\n  - Translates concept to multiple languages\n  - Computes embeddings & similarity matrices\n  - Returns PCA projections, attention maps, translations\n- `POST /api/embed/layers` → Per-layer embeddings\n- `POST /api/cross-attention/per-head` → Per-head attention decomposition\n- `POST /api/experiment/swadesh` → Swadesh convergence ranking\n- `POST /api/experiment/phylogenetic` → Language distance matrix\n- `POST /api/experiment/cognate-entropy` → Attention entropy analysis\n- `POST /api/experiment/color-circle` → Color term centroid projection\n- `POST /api/experiment/colexification` → CLICS² colexification test\n- `POST /api/experiment/neuron-overlap` → FFN neuron activation overlap\n\nRequest models: Pydantic models for type validation\n\n#### 2. `backend/app/modeling.py` (377 lines) — Core ML functions\nModel: Meta NLLB-200 (default: `facebook/nllb-200-distilled-600M`)\n\nFunctions:\n- `translate_text()`: NLLB translation\n- `embed_text()`: Sentence embeddings (final encoder layer, mean pooling)\n- `embed_text_all_layers()`: Per-layer embeddings\n- `embed_text_batch()`: Batch embedding computation\n- `sentence_similarity_matrix()`: Cosine similarity matrix\n- `sentence_similarity_matrix_corrected()`: ABTT isotropy-corrected similarity\n- `project_embeddings()`: PCA projection (2D/3D)\n- `project_embeddings_mean_centered()`: Language-mean-centered PCA\n- `cross_attention_map()`: Cross-attention heatmaps (averaged across layers/heads)\n- `cross_attention_map_per_head()`: Per-head attention decomposition\n- `attention_entropy()`: Attention distribution entropy\n- `neuron_activation_mask()`: FFN activation masks (top-k threshold)\n- `neuron_overlap_matrix()`: Jaccard overlap of activated neurons\n- `abtt_correct()`: Anisotropy correction (subtract mean + top-k PCs)\n\nThread-safe model loading with lazy initialization\n\n#### 3. `backend/app/benchmarks.py` (305 lines) — Research experiments\nValidation functions:\n- `load_swadesh_corpus()`: Loads Swadesh 100 dataset\n- `load_color_terms()`: Loads Berlin & Kay color terms\n- `swadesh_convergence_ranking()`: Ranks concepts by cross-lingual similarity\n- `compute_swadesh_embedding_distances()`: Language-pair distance matrix\n- `colexification_test()`: Mann-Whitney U test (colexified vs non-colexified pairs)\n- `mantel_test()`: Phylogenetic correlation test (Spearman + permutation)\n\nLanguage mappings:\n- `NLLB_TO_ISO`: NLLB codes → ISO 639-3\n- `NLLB_TO_ASJP`: NLLB codes → ASJP database codes\n- `LANGUAGE_FAMILY_MAP`: Language → family mapping\n\nData:\n- `COLEXIFIED_PAIRS`: 50 frequently colexified pairs (CLICS²)\n- `NON_COLEXIFIED_PAIRS`: 50 never-colexified pairs\n\n---\n\n### Data files\n\n#### 1. `backend/app/data/swadesh_100.json`\n- Swadesh 100 core vocabulary\n- 40 languages (NLLB codes)\n- 101 concepts with translations\n- Languages: English, Spanish, French, German, Russian, Hindi, Chinese, Japanese, Arabic, Turkish, etc.\n- Structure: `{metadata, languages: [{code, name, family}], concepts: {concept_name: {lang_code: translation}}}`\n\n#### 2. `backend/app/data/color_terms.json`\n- Berlin & Kay 11 basic color terms\n- 30 languages\n- Colors: black, white, red, green, yellow, blue, brown, purple, pink, orange, grey\n- Structure: `{metadata, languages: [{code, name}], colors: {color_name: {lang_code: translation}}}`\n\n---\n\n### What the app does\n\n#### Purpose\nInteractive web app for analyzing how multilingual translation models (NLLB-200) represent equivalent concepts across languages. Combines NLP interpretability with cognitive science and historical linguistics.\n\n#### Main workflow\n1. User inputs:\n   - Concept (e.g., \"tree\")\n   - Source language (default: English)\n   - Context template (e.g., \"I saw a {word} near the river.\")\n   - Target languages (selectable, 80+ options)\n2. Backend processing:\n   - Translates concept to all target languages\n   - Computes encoder embeddings for each translation\n   - Projects embeddings to 2D/3D via PCA\n   - Computes pairwise cosine similarity matrix\n   - Extracts cross-attention maps (source→target token alignment)\n3. Visualizations:\n   - 3D PCA scatter plot (colored by language family)\n   - Similarity heatmap (grouped by family)\n   - Cross-attention heatmaps (unified + per-language detail)\n   - Translation outputs\n\n#### Scientific experiments\n1. Swadesh convergence: Ranks core vocabulary by cross-lingual embedding similarity\n2. Color circle: Projects color term centroids to test Berlin & Kay universals\n3. Colexification: Tests if colexified pairs have higher similarity (CLICS²)\n4. Phylogenetic distance: Computes language distance matrix over Swadesh vocabulary (prep for Mantel test)\n\n#### Technical architecture\n- Backend: FastAPI (Python)\n- ML framework: PyTorch + Hugging Face Transformers\n- Model: Meta NLLB-200 (encoder-decoder transformer)\n- Frontend: Vanilla JavaScript + Plotly.js\n- Dependencies: numpy, scikit-learn, scipy, sentencepiece, safetensors\n\n---\n\n### Key features\n\n1. Multilingual support: 80+ languages across major families\n2. Visualization: Interactive 3D plots, heatmaps, attention maps\n3. Research experiments: Built-in validation against linguistic datasets\n4. Isotropy correction: ABTT correction for similarity matrices\n5. Mean-centering: Language-mean-centered PCA projection\n6. Attention analysis: Cross-attention visualization and per-head decomposition\n7. Batch processing: Efficient batch embedding computation\n\n---\n\n### Research context\n\nFrom `research/executive_summary.md`:\n- Bridges NLP interpretability, cognitive science, and historical linguistics\n- Tests hypotheses about language-neutral conceptual representations\n- Validates against ASJP, CLICS², Berlin & Kay, Multi-SimLex\n- Roadmap includes per-layer analysis, phylogenetic correlation, resource-level asymmetry\n\n---\n\n### Dependencies (`backend/requirements.txt`)\n```\nfastapi\nnumpy\nscikit-learn\nscipy\nsentencepiece\nsafetensors\ntorch\ntransformers\nuvicorn\n```\n\n---\n\n### Summary\n\nInterpretCognates is a research tool for analyzing multilingual neural translation models. It provides an interactive interface for exploring cross-lingual semantic representations, with built-in experiments validated against linguistic datasets. The codebase is organized with a FastAPI backend, vanilla JS frontend, and research documentation. The system is functional and ready for scientific analysis, with a roadmap for deeper mechanistic interpretability experiments."}]}}