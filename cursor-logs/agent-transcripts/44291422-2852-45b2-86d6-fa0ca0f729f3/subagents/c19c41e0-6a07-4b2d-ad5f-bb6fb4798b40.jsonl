{"role":"user","message":{"content":[{"type":"text","text":"<user_query>\nYou are working on the InterpretCognates project at /Users/kylemathewson/InterpretCognates.\n\nYOUR TASK: Modify ONLY two files — `backend/app/main.py` and `backend/app/benchmarks.py` — to add new validation experiment endpoints. Do NOT modify any other files.\n\nIMPORTANT: This is a Python 3.9 environment. Do NOT use `X | Y` union type syntax. Use `Optional[X]` from typing instead.\n\nRead both files first to understand their current structure, then make these changes:\n\n## 1. In benchmarks.py, add these functions:\n\n### load_non_swadesh_corpus()\n- Loads `/backend/app/data/non_swadesh_60.json` (same format as swadesh_100.json, created by another agent)\n- Returns the parsed JSON dict\n\n### swadesh_vs_non_swadesh_comparison(swadesh_embeddings, non_swadesh_embeddings, languages)\n- Takes two dicts of {concept: {lang: vector}} and computes convergence rankings for both\n- Computes mean convergence for each set\n- Runs scipy.stats.mannwhitneyu(swadesh_sims, non_swadesh_sims, alternative=\"greater\") \n- Returns dict with: swadesh_mean, swadesh_std, non_swadesh_mean, non_swadesh_std, U_statistic, p_value, swadesh_sims (list), non_swadesh_sims (list)\n- The \"sims\" lists are the per-concept mean similarities\n\n### conceptual_store_metric(concept_embeddings, languages)\n- Takes {concept: {lang: vector}} and list of language codes\n- Computes: \n  a) For each concept, mean within-concept distance (distances between all language versions of that concept)\n  b) For each concept pair, mean between-concept distance  \n  c) Ratio = mean_between / mean_within (higher = better separation)\n  d) Same computation after subtracting per-language mean vectors (mean-centering)\n- Returns dict with: raw_ratio, centered_ratio, improvement_factor (centered/raw), num_concepts, num_languages\n\n## 2. In main.py, add these endpoints:\n\n### POST /api/experiment/swadesh (MODIFY existing)\n- Add optional `isotropy_corrected: bool = False` field to a new request model `SwadeshRequest`\n- When True, apply `abtt_correct()` (already imported from modeling) to ALL embedding vectors before computing convergence\n- Keep the existing behavior as default\n\n### POST /api/experiment/swadesh-comparison\n- Loads both Swadesh and non-Swadesh corpora\n- Embeds both sets using embed_text_batch\n- Computes comparison using swadesh_vs_non_swadesh_comparison()\n- Also returns both convergence rankings\n- Response: { swadesh: {num_concepts, num_languages, total_embeddings, convergence_ranking}, non_swadesh: {same structure}, comparison: {swadesh_mean, non_swadesh_mean, U_statistic, p_value, swadesh_sims, non_swadesh_sims} }\n\n### POST /api/experiment/conceptual-store-metric  \n- Uses Swadesh corpus embeddings\n- Calls conceptual_store_metric()\n- Response: { raw_ratio, centered_ratio, improvement_factor, num_concepts, num_languages }\n\n### GET /validation\n- Serves static/validation.html (created by another agent)\n\n### GET /api/data/non-swadesh\n- Returns the non-Swadesh corpus JSON\n\n## Key imports already available in modeling.py:\n- abtt_correct(vectors, k=3) -> list[np.ndarray]\n- embed_text_batch(texts, langs) -> list[np.ndarray]\n- project_embeddings_mean_centered(vectors, labels, language_ids) -> dict\n\nRemember: \n- Python 3.9 — use Optional[float] not float | None, use List[str] not list[str] in type hints for function signatures that might cause issues\n- Use the virtual environment at backend/venv\n- Read the existing files first to understand the patterns\n- Keep the same coding style as existing code\n- The non_swadesh_60.json file will be created by another agent in the same format as swadesh_100.json\n\nReturn a summary of all endpoints added and their response shapes.\n</user_query>"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Let me start by reading both files to understand their current structure, then make the required changes."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Let me also check the `abtt_correct` function signature in modeling.py and the swadesh_100.json format.\n\nNow let me also check what's available in modeling.py to understand the `abtt_correct` function signature."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now I have a clear picture of both files. Let me also verify the existing imports in modeling.py for `abtt_correct`.\n\nNow I have a good understanding of both files. Let me also check what's in the modeling.py imports to make sure `abtt_correct` is there and understand how it's used."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now I have everything I need. Let me create the todo list and start implementing."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now add the three new functions at the end of `benchmarks.py`:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now update `main.py`. First, update the imports from benchmarks:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now add the `typing` import and `SwadeshRequest` model:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now add the `SwadeshRequest` model after the existing request models:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now modify the existing `/api/experiment/swadesh` endpoint to accept the request body and support isotropy correction:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now add the new endpoints at the end of the file:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Now let me verify both files look correct by reading them and checking for linter errors."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"No linter errors. Both files look correct. Let me mark the task as complete."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Here's a summary of all changes made:\n\n## `benchmarks.py` — 3 new functions added\n\n**`load_non_swadesh_corpus()`** — Loads `data/non_swadesh_60.json` and returns the parsed dict.\n\n**`swadesh_vs_non_swadesh_comparison(swadesh_embeddings, non_swadesh_embeddings, languages)`** — Computes convergence rankings for both sets, extracts per-concept mean similarities, runs a one-sided Mann-Whitney U test. Returns:\n```python\n{ \"swadesh_mean\", \"swadesh_std\", \"non_swadesh_mean\", \"non_swadesh_std\",\n  \"U_statistic\", \"p_value\", \"swadesh_sims\", \"non_swadesh_sims\" }\n```\n\n**`conceptual_store_metric(concept_embeddings, languages)`** — Computes within-concept distances (all language pair combinations per concept), between-concept distances (centroid pairs), their ratio, then repeats after per-language mean-centering. Returns:\n```python\n{ \"raw_ratio\", \"centered_ratio\", \"improvement_factor\", \"num_concepts\", \"num_languages\" }\n```\n\n## `main.py` — 5 endpoints added/modified\n\n| Endpoint | Method | Change | Response shape |\n|---|---|---|---|\n| `/api/experiment/swadesh` | POST | **Modified** — accepts optional `SwadeshRequest` body with `isotropy_corrected: bool`. When true, applies `abtt_correct()` to all vectors before computing convergence. | `{ num_concepts, num_languages, total_embeddings, convergence_ranking }` |\n| `/api/experiment/swadesh-comparison` | POST | **New** — embeds both Swadesh and non-Swadesh corpora, runs comparison | `{ swadesh: {num_concepts, num_languages, total_embeddings, convergence_ranking}, non_swadesh: {same}, comparison: {swadesh_mean, non_swadesh_mean, U_statistic, p_value, swadesh_sims, non_swadesh_sims} }` |\n| `/api/experiment/conceptual-store-metric` | POST | **New** — embeds Swadesh corpus, computes conceptual store metric | `{ raw_ratio, centered_ratio, improvement_factor, num_concepts, num_languages }` |\n| `/validation` | GET | **New** — serves `static/validation.html` | HTML file |\n| `/api/data/non-swadesh` | GET | **New** — returns the non-Swadesh corpus JSON | JSON corpus dict |\n\nA shared `_embed_corpus()` helper was also added to avoid duplicating the embedding loop across the new endpoints."}]}}