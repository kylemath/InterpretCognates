{"role":"user","message":{"content":[{"type":"text","text":"<user_query>\nExplore the directory /Users/kylemathewson/InterpretCognates/ at the top level and also look at the research/ directory. I need to understand:\n1. The overall project structure (what directories exist)\n2. What data files exist\n3. What the README says about the project\n4. What research documents exist and their key content\n5. Any existing analysis scripts outside of the web app\n\nReturn a comprehensive summary of the project structure, its purpose, and any existing analysis code.\n</user_query>"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Exploring the project structure and gathering information. Starting with the top-level directory and key files."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Exploring the backend directory and searching for data files and analysis scripts:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Exploring the backend structure and searching for analysis scripts:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Checking the backend structure and scripts:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Reading the beginning of the script to understand its purpose:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"## Project Structure Summary\n\n### Top-Level Directory Structure\n\n**Main directories:**\n- `/backend/` - FastAPI web application backend\n- `/research/` - Research documentation and meeting notes\n\n**Top-level files:**\n- `README.md` - Project overview and setup instructions\n\n### Backend Structure (`/backend/app/`)\n\n**Core Python modules:**\n- `main.py` - FastAPI application with REST API endpoints\n- `modeling.py` - Core NLLB model interaction functions (embedding, attention, similarity)\n- `benchmarks.py` - Experimental analysis functions (Swadesh tests, phylogenetic correlation, etc.)\n- `scripts/expand_swadesh_corpus.py` - Utility script to expand Swadesh corpus from 40 to 142 languages\n\n**Data directory (`/backend/app/data/`):**\n- `swadesh_100.json` - 101 Swadesh concepts × 142 languages (expanded from 40)\n- `non_swadesh_60.json` - 60 culturally-specific concepts × 40 languages (comparison corpus)\n- `color_terms.json` - 11 Berlin & Kay basic color terms × 30+ languages\n\n**Static files (`/backend/app/static/`):**\n- `index.html`, `app.js`, `styles.css` - Main interactive analysis interface\n- `swadesh_detail.html/js/css` - Swadesh convergence analysis page\n- `validation.html/js/css` - Six-panel validation experiments dashboard\n\n### Research Documents (`/research/`)\n\n1. **`executive_summary.md`** (392 lines)\n   - Synthesis of Feb 22, 2026 interdisciplinary meeting\n   - 7 core scientific questions\n   - 10 prioritized development tasks\n   - 3 novel hypotheses\n   - 14-day sprint roadmap\n\n2. **`sprint1_report.md`** (345 lines)\n   - Status update from Feb 23, 2026\n   - Completed: isotropy correction, mean-centering PCA, Swadesh corpus, validation tests\n   - Novel directions: orthographic/phonetic variance decomposition, semantic offset invariance\n   - Technical debt and next steps\n\n3. **`meeting.md`** (280 lines)\n   - Transcript of Feb 22, 2026 research meeting\n   - Discussion between NLP interpretability (Agent A) and cognitive science (Agent B) perspectives\n   - Priority-ranked experiments\n   - Codebase gaps and action items\n\n4. **`agent_a_bib.md`** (602 lines)\n   - Bibliography: mechanistic interpretability, multilingual NLP\n   - 10 research ideas with code sketches\n   - Key papers: Voita et al., Chang et al., Rajaee & Pilehvar, Foroutan et al.\n\n5. **`agent_b_bib.md`** (723 lines)\n   - Bibliography: cognitive science, psycholinguistics, bilingualism\n   - 10 research ideas bridging cognitive science and NLP\n   - Key papers: BIA+, RHM, Correia et al., Thierry & Wu, Berlin & Kay, Swadesh\n\n### Project Purpose\n\n**Goal:** Interactive web app for probing how multilingual translation networks (NLLB-200) represent equivalent concepts across languages.\n\n**Key research questions:**\n1. Does NLLB's encoder contain a language-neutral conceptual store?\n2. Does the representation space encode phylogenetic language relationships?\n3. Does it exhibit resource-level asymmetry (RHM prediction)?\n4. At which encoder layer does cross-lingual semantic convergence peak?\n5. Do specific cross-attention heads function as universal semantic alignment heads?\n6. Does the embedding space reflect universal conceptual associations (CLICS² colexification)?\n7. How does NLLB's geometry compare to encoder-only models (XLM-R)?\n\n**Model:** Uses Meta NLLB-200 (specifically `facebook/nllb-200-distilled-600M` or `1.3B`) through Hugging Face Transformers.\n\n### Current Features (MVP)\n\n- Translate source concepts to multiple target languages\n- Compute multilingual sentence embeddings from NLLB encoder states\n- Project embeddings to 2D/3D with PCA for visualization\n- Compute pairwise cosine similarity matrices across languages\n- Visualize source-target cross-attention heatmaps per target language\n- Swadesh convergence analysis with orthographic/phonetic decomposition\n- Six validation experiments (isotropy correction, Swadesh vs non-Swadesh, CLICS², conceptual store metric, phylogenetic distance, semantic offset invariance)\n\n### Analysis Scripts Outside Web App\n\n**Single utility script:**\n- `/backend/app/scripts/expand_swadesh_corpus.py` - Expands Swadesh corpus from 40 to 142 languages (utility, not analysis)\n\n**Note:** Analysis is integrated into the web app via API endpoints in `main.py` and analysis functions in `benchmarks.py`. There are no standalone analysis scripts; experiments run through the web interface or API calls.\n\n### Data Files\n\n**Structured JSON corpora:**\n1. **Swadesh 100** (`swadesh_100.json`) - 101 concepts × 142 languages\n2. **Non-Swadesh 60** (`non_swadesh_60.json`) - 60 culturally-specific concepts × 40 languages\n3. **Color Terms** (`color_terms.json`) - 11 basic color terms × 30+ languages\n\nAll data files include language metadata (NLLB codes, language names, language families) and concept translations.\n\n### Key Scientific Contributions\n\n1. **Orthographic/Phonetic Variance Decomposition** - Separates surface-form similarity from semantic convergence\n2. **Semantic Offset Invariance** - Tests whether concept relationships (e.g., man→woman) are translationally invariant\n3. **Swadesh vs Non-Swadesh Comparison** - Tests cultural stability hypothesis in neural representation space\n4. **Conceptual Store Metric** - Quantifies language-neutral vs language-specific geometry\n5. **Phylogenetic Correlation Infrastructure** - Prepares for Mantel test against ASJP phonetic distances\n\nThe project bridges NLP interpretability and cognitive science, with infrastructure for testing hypotheses about multilingual representation geometry."}]}}