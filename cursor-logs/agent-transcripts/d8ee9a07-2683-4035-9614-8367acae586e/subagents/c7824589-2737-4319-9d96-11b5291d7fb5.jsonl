{"role":"user","message":{"content":[{"type":"text","text":"<user_query>\nTHOROUGH audit of ASJP (Automated Similarity Judgement Program) data in this project. I need to know: is this project using REAL ASJP v19+ phonetic distance data downloaded from an external source, or is it using fabricated/approximated/hardcoded distance values?\n\nSearch for:\n1. Any ASJP-related data files (JSON, CSV, etc.) in the project\n2. Functions that compute or load ASJP distances (look in backend/app/benchmarks.py, backend/app/scripts/, and any other Python files)\n3. Any hardcoded distance matrices or taxonomy-based approximations\n4. Any downloads or references to actual ASJP databases\n\nKey things to check:\n- Is there an actual ASJP data file downloaded from asjp.clld.org or similar?\n- Or are the distances computed from a hardcoded taxonomy/classification scheme?\n- Look for functions like compute_asjp_distance_matrix, asjp_distance, etc.\n- Check if there are hardcoded distance values between language families\n\nReturn the FULL source code of any ASJP distance computation functions and any hardcoded distance data. This is a data integrity audit.\n</user_query>"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Auditing ASJP data usage. Searching for ASJP-related files, data, and code."}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Searching for ASJP data files and download scripts:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Checking the data directory and examining the phylogenetic results file:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"Checking for any download scripts or references to external ASJP data sources:"}]}}
{"role":"assistant","message":{"content":[{"type":"text","text":"## ASJP Data Integrity Audit Report\n\n### Summary\nThe project uses approximated/hardcoded ASJP distance values, not real ASJP v19+ phonetic distance data from an external source.\n\n---\n\n### Findings\n\n#### 1. No ASJP data files found\n- No JSON, CSV, or other ASJP data files in the project\n- No files matching `*asjp*` or `*ASJP*` patterns\n- No ASJP data in `/backend/app/data/` (only Swadesh corpus, color terms, and results)\n\n#### 2. No download scripts or external data integration\n- No code downloads from `asjp.clld.org` or any external ASJP source\n- No `urllib`, `requests`, `wget`, or `curl` calls for ASJP data\n- No data loading functions for ASJP files\n\n#### 3. Fabricated distance computation\n\nThe ASJP distances are computed using a taxonomy-based approximation in `compute_asjp_distance_matrix()`:\n\n**Location:** `/Users/kylemathewson/InterpretCognates/backend/app/benchmarks.py` (lines 821-858)\n\n**Full source code:**\n\n```python:821:858:backend/app/benchmarks.py\ndef compute_asjp_distance_matrix(\n    languages: List[str],\n) -> Tuple[np.ndarray, List[str]]:\n    \"\"\"Approximate ASJP LDND phonetic distance matrix.\n\n    Based on linguistic taxonomy and published ASJP benchmarks (Wichmann et al.\n    2010, Holman et al. 2011).  For production use, integrate actual ASJP v19+\n    database values downloaded from asjp.clld.org.\n\n    Returns (distance_matrix, filtered_languages) where only languages present\n    in NLLB_TO_ASJP are included.\n    \"\"\"\n    mapped = [l for l in languages if l in NLLB_TO_ASJP]\n    n = len(mapped)\n    rng = np.random.default_rng(42)\n    noise = rng.uniform(-0.04, 0.04, (n, n))\n    noise = (noise + noise.T) / 2\n    np.fill_diagonal(noise, 0.0)\n\n    dist = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i + 1, n):\n            fam_a = LANGUAGE_FAMILY_MAP.get(mapped[i], \"Unknown\")\n            fam_b = LANGUAGE_FAMILY_MAP.get(mapped[j], \"Unknown\")\n\n            if fam_a == fam_b:\n                base = _WITHIN_SUBFAMILY_LDND.get(fam_a, 0.50)\n            elif _broad_family(fam_a) == _broad_family(fam_b) == \"Indo-European\":\n                pair_key = frozenset({fam_a, fam_b})\n                base = _IE_CLOSE_BRANCHES.get(pair_key, _IE_INTER_BRANCH_DEFAULT)\n            else:\n                base = _CROSS_FAMILY_DEFAULT\n\n            d = float(np.clip(base + noise[i, j], 0.01, 0.99))\n            dist[i, j] = d\n            dist[j, i] = d\n\n    return dist, mapped\n```\n\n#### 4. Hardcoded distance values\n\n**Location:** `/Users/kylemathewson/InterpretCognates/backend/app/benchmarks.py` (lines 797-818)\n\n**Full source code:**\n\n```python:797:818:backend/app/benchmarks.py\n_WITHIN_SUBFAMILY_LDND: Dict[str, float] = {\n    \"IE: Romance\": 0.35, \"IE: Germanic\": 0.42, \"IE: Slavic\": 0.33,\n    \"IE: Indo-Iranian\": 0.48, \"IE: Celtic\": 0.45, \"IE: Baltic\": 0.32,\n    \"Turkic\": 0.40, \"Dravidian\": 0.44, \"Austronesian\": 0.52,\n    \"Niger-Congo\": 0.58, \"Afro-Asiatic\": 0.62, \"Sino-Tibetan\": 0.58,\n    \"Uralic\": 0.48, \"Austroasiatic\": 0.47, \"Tai-Kadai\": 0.38,\n    \"Japonic & Koreanic\": 0.78, \"Nilo-Saharan\": 0.58,\n    \"Indigenous Americas\": 0.70, \"Creole\": 0.72,\n}\n\n_IE_CLOSE_BRANCHES: Dict[frozenset, float] = {\n    frozenset({\"IE: Slavic\", \"IE: Baltic\"}): 0.52,\n    frozenset({\"IE: Romance\", \"IE: Hellenic\"}): 0.60,\n    frozenset({\"IE: Hellenic\", \"IE: Armenian\"}): 0.63,\n    frozenset({\"IE: Indo-Iranian\", \"IE: Armenian\"}): 0.62,\n    frozenset({\"IE: Slavic\", \"IE: Indo-Iranian\"}): 0.64,\n    frozenset({\"IE: Romance\", \"IE: Celtic\"}): 0.63,\n    frozenset({\"IE: Germanic\", \"IE: Celtic\"}): 0.62,\n}\n\n_IE_INTER_BRANCH_DEFAULT = 0.68\n_CROSS_FAMILY_DEFAULT = 0.93\n```\n\n#### 5. How the approximation works\n\n1. Taxonomy lookup: maps each language to a family/subfamily via `LANGUAGE_FAMILY_MAP`\n2. Three-tier system:\n   - Same subfamily: uses `_WITHIN_SUBFAMILY_LDND` (e.g., 0.35 for Romance)\n   - Cross-branch Indo-European: uses `_IE_CLOSE_BRANCHES` or default 0.68\n   - Cross-family: uses 0.93\n3. Random noise: adds uniform noise [-0.04, 0.04] with fixed seed (42) to simulate variation\n4. Clipping: values clamped to [0.01, 0.99]\n\n#### 6. Explicit acknowledgment in code\n\nThe code comments acknowledge this is not real data:\n\n```python:87:91:backend/app/benchmarks.py\n# Approximate ASJP LDND phonetic distances between language families.\n# These are placeholders; for production use, load from the ASJP database download.\n# Source: JÃ¤ger (2018), ASJP v19 pairwise LDND values.\n# Format: (lang_a_nllb, lang_b_nllb) -> LDND distance (0 = identical, 1 = maximally distant)\n# Full matrix should be loaded from asjp.clld.org exports.\n```\n\nAnd in the function docstring:\n\n```python:824:828:backend/app/benchmarks.py\n\"\"\"Approximate ASJP LDND phonetic distance matrix.\n\nBased on linguistic taxonomy and published ASJP benchmarks (Wichmann et al.\n2010, Holman et al. 2011).  For production use, integrate actual ASJP v19+\ndatabase values downloaded from asjp.clld.org.\n```\n\n#### 7. Documentation references\n\nMultiple documents note that real ASJP data integration is deferred:\n\n- `research/sprint1_report.md`: \"ASJP distance data not yet integrated\"\n- `research/executive_summary.md`: Mentions downloading ASJP data as a future task\n- `backend/app/static/blog.html`: States \"current ASJP distances are taxonomy-based approximations\"\n- `backend/app/static/validation.js`: Notes \"ASJP distances are taxonomy-based estimates\"\n\n---\n\n### Conclusion\n\nThe project uses approximated ASJP distances based on linguistic taxonomy, not real ASJP v19+ phonetic distance data. The implementation:\n- Uses hardcoded family-level distance values\n- Adds random noise to simulate variation\n- Operates on a three-tier taxonomy system\n- Explicitly documents this as a placeholder\n\nNo actual ASJP database files are present, and there is no code to download or load real ASJP data from `asjp.clld.org` or any other source.\n\n### Recommendations\n\nFor publication-ready results, integrate real ASJP v19+ data by:\n1. Downloading the ASJP pairwise LDND distance matrix from `asjp.clld.org`\n2. Mapping ASJP language codes to NLLB codes via the existing `NLLB_TO_ASJP` mapping\n3. Replacing `compute_asjp_distance_matrix()` with a function that loads the real data\n4. Removing the hardcoded taxonomy-based approximation\n\nThe infrastructure (Mantel test, language code mappings) is already in place; only the actual ASJP data integration is missing."}]}}