# Reproducing the paper (no placeholders)

This paper is built from **derived JSON artifacts** in `docs/data/`, which are generated by **running the NLLB-200 model** on the included corpora and then running analysis scripts.

The pipeline is designed to **fail rather than fabricate**: if an external dataset is missing (e.g., ASJP CLDF tables), the build will stop with instructions.

## Prerequisites

- **Python**: `python3`
- **LaTeX**: `pdflatex`, `bibtex`
- **Disk**: enough space for model weights + downloaded ASJP CLDF tables

## One-time: fetch ASJP CLDF tables (required for Mantel/ASJP)

The repo vendors an ASJP CLDF directory, but `forms.csv` and `languages.csv` may be absent in some checkouts.

From the repository root:

```bash
PYTHONPATH=backend python3 -m app.scripts.fetch_asjp_cldf
```

This downloads:

- `backend/app/data/external/asjp/lexibank-asjp-*/cldf/languages.csv`
- `backend/app/data/external/asjp/lexibank-asjp-*/cldf/forms.csv`

## Generate all paper data artifacts from raw corpora + model

From `paper/`:

```bash
bash build.sh
```

What `build.sh` does:

- Creates/uses a virtualenv at `paper/scripts/.venv`
- Installs `paper/scripts/requirements.txt`
- Runs `paper/scripts/precompute_paper_data.py` to generate `docs/data/*.json` from real computations
- Runs `paper/scripts/generate_figures.py` and `paper/scripts/generate_stats.py`
- Compiles LaTeX into `paper/main.pdf`

## Outputs

- **Derived experiment JSONs**: `docs/data/*.json`
- **Figures**: `paper/figures/*.pdf`
- **LaTeX macros**: `paper/output/stats.tex`
- **Compiled PDF**: `paper/main.pdf`

## Notes on runtime

- The script `paper/scripts/precompute_paper_data.py` runs model forward passes over the Swadesh corpus and additional baselines; this can take significant time on CPU.
- The layerwise analysis is computed on a **40-language subset** (see `docs/data/layerwise_metrics.json`) to keep it tractable while still typologically diverse.

