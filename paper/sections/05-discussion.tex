\section{Discussion}

\subsection{Structural Parallels with Cognitive Models}

The geometric structure we observe in NLLB-200's encoder bears striking parallels to architectures proposed in the cognitive science of bilingualism.
The conceptual store experiment, in which mean-centering per language improves the between-concept to within-concept variance ratio by a factor of $\ConceptualStoreImprovement{}\times$, provides direct geometric evidence for a language-neutral semantic core.
This finding mirrors Correia et al.'s fMRI results showing that semantic representations in the anterior temporal lobe can be decoded across languages, localizing a language-independent conceptual hub in biological neural tissue \citep{correia2014}.
In both systems---biological and artificial---meaning appears to be organized along axes that are invariant to the language of expression, with language-specific information superimposed as a removable offset.

The architecture of NLLB-200 also maps naturally onto the Bilingual Interactive Activation Plus (BIA+) model of visual word recognition \citep{dijkstra2002}.
In BIA+, a language-nonselective identification system activates lexical candidates from all known languages simultaneously, while a separate task-decision system gates output to a single language.
NLLB-200's shared encoder plays the role of the identification system: it maps inputs from all \NumLanguages{} languages into a common representational space without language-specific gating.
The forced BOS token on the decoder side, which specifies the target language, functions as the task-decision system, imposing language constraints only at generation time.
This architectural correspondence suggests that the encoder's language-neutral geometry is not an incidental byproduct of training but a functional analogue of the nonselective access mechanism that BIA+ posits for human bilinguals.
A similar logic applies to the Revised Hierarchical Model \citep{kroll2010}, in which proficient bilinguals develop direct conceptual links that bypass lexical mediation---precisely the kind of shared semantic structure our mean-centering analysis reveals.

The offset invariance result, with a mean cosine similarity of $\OffsetMeanConsistency{}$ across \OffsetNumPairs{} concept pairs, extends Mikolov et al.'s \citeyearpar{mikolov2013} observation that monolingual word embeddings encode relational structure as linear offsets.
Our finding demonstrates that this regularity holds not only within a single language but across typologically diverse languages simultaneously, consistent with the hypothesis that NLLB-200 encodes a language-universal relational geometry.

\subsection{Limitations}

Several limitations temper the strength of our conclusions.

\paragraph{Carrier sentence confound.}
All contextual embeddings were extracted using a single English-derived carrier sentence (``I saw a \{word\} near the river''), translated into each target language.
This template presupposes specific syntactic structures (SVO word order, definite/indefinite articles, spatial prepositions) that are far from universal.
When translated into languages with different word orders, case systems, or zero-article grammars, the carrier sentence's structure---not just the target word---varies systematically with typological distance.
This confounds the embedding signal: part of the measured cross-lingual similarity may reflect shared carrier-sentence structure rather than shared concept semantics.
Future work should control for this by averaging over multiple carrier templates or by using decontextualized embeddings as a baseline.

\paragraph{Conceptual store improvement.}
The $\ConceptualStoreImprovement{}\times$ improvement in concept separability after mean-centering, while in the predicted direction, falls short of the $2\times$ threshold informally predicted from cognitive parallels with \citet{correia2014}.
This may reflect the limited expressiveness of the 600M-parameter distilled model compared to the full 3.3B-parameter NLLB-200, or the homogenizing effect of a single carrier template on per-language variance.
The improvement factor should be interpreted as evidence for partial factoring of language identity from conceptual content, not as confirmation of a clean conceptual store.

\paragraph{Additional limitations.}
All experiments use a single model checkpoint; we have not validated whether the patterns generalize across architectures or scales \citep{nllbteam2022}.
The Mantel correlation, while significant ($\rho = \MantelRho{}$, $p = \MantelP{}$), is modest, explaining approximately $\MantelRho{}^2 \approx 2\%$ of the variance in pairwise language distances.
Translations for the non-Swadesh comparison vocabulary were generated by a language model rather than verified by native speakers, introducing potential noise.
All analyses operate on the final encoder layer; the trajectory across layers---where qualitative phase transitions in representation type are expected \citep{voita2019,tenney2019}---remains unexplored.
Finally, NLLB-200 was trained on parallel corpora, not through embodied language acquisition.
The cognitive parallels we draw are structural analogies, not claims of mechanistic identity \citep{thierry2007}.

\subsection{Broader Implications}

Despite these caveats, the convergence of evidence across our six experiments points toward a substantive conclusion: NLLB-200 has internalized aspects of conceptual structure that transcend individual languages.
The colexification result is particularly telling.
Concept pairs that share a lexical form across unrelated languages---a hallmark of universal conceptual association \citep{list2018}---are embedded more closely than non-colexified pairs ($p = \ColexP{}$, Cohen's $d = \ColexCohenD{}$), suggesting that the model has learned associative structure that mirrors cross-linguistic cognitive patterns.
This echoes recent neuroscience findings of a universal language network whose functional topography is preserved across typologically distant languages \citep{malikmoraleda2024}.

The phylogenetic correlation, while modest, demonstrates that translation co-occurrence statistics alone---without any explicit genealogical supervision---are sufficient to partially recapitulate thousands of years of language divergence.
This is consistent with the view that statistical regularities in parallel text carry a phylogenetic signal, much as cognate frequency in the Swadesh list carries one for historical linguists.

Taken together, these findings support the interpretation that modern multilingual Transformers are not merely mapping between surface forms but have learned something about the deep structure of human language \citep{chang2022}.
If confirmed across models and scales, this would position large-scale translation models as computational testbeds for theories of language universals---systems in which hypotheses about shared conceptual structure can be tested with a precision and breadth that is difficult to achieve in human behavioral or neuroimaging experiments.
