\section{Discussion}

\subsection{Structural Parallels with Cognitive Models}

The geometric structure we observe in NLLB-200's encoder bears striking parallels to architectures proposed in the cognitive science of bilingualism.
The conceptual store experiment, in which mean-centering per language improves the between-concept to within-concept variance ratio by a factor of $\ConceptualStoreImprovement{}\times$, provides direct geometric evidence for a language-neutral semantic core.
This finding mirrors Correia et al.'s fMRI results showing that semantic representations in the anterior temporal lobe can be decoded across languages, localizing a language-independent conceptual hub in biological neural tissue \citep{correia2014}.
In both systems---biological and artificial---meaning appears to be organized along axes that are invariant to the language of expression, with language-specific information superimposed as a removable offset.

The architecture of NLLB-200 also maps naturally onto the Bilingual Interactive Activation Plus (BIA+) model of visual word recognition \citep{dijkstra2002}.
In BIA+, a language-nonselective identification system activates lexical candidates from all known languages simultaneously, while a separate task-decision system gates output to a single language.
NLLB-200's shared encoder plays the role of the identification system: it maps inputs from all \NumLanguages{} languages into a common representational space without language-specific gating.
The forced BOS token on the decoder side, which specifies the target language, functions as the task-decision system, imposing language constraints only at generation time.
This architectural correspondence suggests that the encoder's language-neutral geometry is not an incidental byproduct of training but a functional analogue of the nonselective access mechanism that BIA+ posits for human bilinguals.
A similar logic applies to the Revised Hierarchical Model \citep{kroll2010}, in which proficient bilinguals develop direct conceptual links that bypass lexical mediation---precisely the kind of shared semantic structure our mean-centering analysis reveals.

The offset invariance result, with a mean cosine similarity of $\OffsetMeanConsistency{}$ across \OffsetNumPairs{} concept pairs, extends Mikolov et al.'s \citeyearpar{mikolov2013} observation that monolingual word embeddings encode relational structure as linear offsets.
Our finding demonstrates that this regularity holds not only within a single language but across typologically diverse languages simultaneously, consistent with the hypothesis that NLLB-200 encodes a language-universal relational geometry.

\subsection{Limitations}

Several limitations temper the strength of our conclusions.
First, all experiments use a single model checkpoint (NLLB-200-distilled-600M, \NumLanguages{} languages); we have not validated whether the patterns generalize across architectures or model scales \citep{nllbteam2022}.
Second, contextual embeddings were extracted using a single carrier sentence template, which may not capture the full distributional behavior of polysemous concepts.
Third, the Mantel correlation between embedding distances and phylogenetic distances, while statistically significant ($\rho = \MantelRho{}$, $p = \MantelP{}$), is modest in magnitude, indicating that embedding geometry captures phylogenetic structure only weakly; much of the variance in language relatedness is not reflected in lexical-level encoder representations.
Fourth, translations for the non-Swadesh comparison vocabulary were generated by a language model rather than verified by native speakers, introducing potential noise.
Fifth, all analyses operate on the final encoder layer; the representational trajectory across layers---which prior work suggests undergoes qualitative phase transitions \citep{voita2019}---remains unexplored.
Finally, NLLB-200 was trained on parallel corpora via a translation objective, not through the embodied, interactive process of natural language acquisition.
The cognitive parallels we draw are therefore structural analogies, not claims of mechanistic identity; the model may arrive at similar geometric solutions for fundamentally different reasons \citep{thierry2007}.

\subsection{Broader Implications}

Despite these caveats, the convergence of evidence across our six experiments points toward a substantive conclusion: NLLB-200 has internalized aspects of conceptual structure that transcend individual languages.
The colexification result is particularly telling.
Concept pairs that share a lexical form across unrelated languages---a hallmark of universal conceptual association \citep{list2018}---are embedded more closely than non-colexified pairs ($p = \ColexP{}$, Cohen's $d = \ColexCohenD{}$), suggesting that the model has learned associative structure that mirrors cross-linguistic cognitive patterns.
This echoes recent neuroscience findings of a universal language network whose functional topography is preserved across typologically distant languages \citep{malikmoraleda2024}.

The phylogenetic correlation, while modest, demonstrates that translation co-occurrence statistics alone---without any explicit genealogical supervision---are sufficient to partially recapitulate thousands of years of language divergence.
This is consistent with the view that statistical regularities in parallel text carry a phylogenetic signal, much as cognate frequency in the Swadesh list carries one for historical linguists.

Taken together, these findings support the interpretation that modern multilingual Transformers are not merely mapping between surface forms but have learned something about the deep structure of human language \citep{chang2022}.
If confirmed across models and scales, this would position large-scale translation models as computational testbeds for theories of language universals---systems in which hypotheses about shared conceptual structure can be tested with a precision and breadth that is difficult to achieve in human behavioral or neuroimaging experiments.
